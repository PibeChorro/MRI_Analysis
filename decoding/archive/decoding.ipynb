{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# LIBRARIES #\n",
    "#############\n",
    "\n",
    "# libraries to interact with the operating system \n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import h5py\n",
    "# libraries for data structuration and calculations\n",
    "import pandas as pd  # to create data frames\n",
    "import numpy as np   # most important numerical calculations\n",
    "# to read in mat files\n",
    "import readmat\n",
    "# needed to extract the run number out of the parentesis of the string in the SPM.mat file\n",
    "import re\n",
    "# library for neuroimaging\n",
    "import nibabel as nib\n",
    "# machine learning algorithms and stuff\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import cross_val_score, PredefinedSplit, permutation_test_score\n",
    "# to check and optimize time performance\n",
    "import time\n",
    "import multiprocessing\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables for permutation testing\n",
    "rng_seed = 1\n",
    "\n",
    "# Number of permutations\n",
    "n_permutations = 10\n",
    "\n",
    "# Number of CPUs\n",
    "max_num_CPU = 24                          # do not use more than that\n",
    "num_CPU = multiprocessing.cpu_count()     # get number of cores\n",
    "# TODO: improve\n",
    "n_proc = min([num_CPU,max_num_CPU])       # set the number of cores that should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    4.0s remaining:    9.2s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    4.0s remaining:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    4.6s finished\n"
     ]
    }
   ],
   "source": [
    "targets = np.asarray(label_df.Labels)\n",
    "chunks = np.asarray(label_df.Chunks)\n",
    "if n_permutations > 0:\n",
    "    res = permutation_test_score(\n",
    "        LDA(solver='lsqr', shrinkage='auto'),\n",
    "        betas,\n",
    "        targets,\n",
    "        groups=chunks,\n",
    "        cv=PredefinedSplit(chunks),\n",
    "        n_permutations=n_permutations,\n",
    "        random_state=rng_seed,\n",
    "        n_jobs=n_proc,\n",
    "        verbose=3)\n",
    "    accuracy = res[0]\n",
    "    null_distribution = res[1]\n",
    "    p_value = res[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if n_permutations > 0:\n",
    "    plt.hist(null_distribution)\n",
    "    y_min, y_max = plt.ylim()\n",
    "    plt.vlines(1/len(label_names), y_min, y_max, color='k', linestyles='--')\n",
    "    plt.vlines(accuracy, y_min, y_max, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/sklearn-decoding/sub-01/ROIs'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df['Chunks'] = (label_df.Runs-1)//2   # The chunks (needed for cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/sklearn-decoding/sub-01/ROI-analysis/hV4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpl/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    5.4s remaining:   12.5s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    5.4s remaining:    2.3s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    7.8s remaining:   18.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    7.9s remaining:    3.4s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "/Users/vpl/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    6.3s remaining:   14.6s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    6.3s remaining:    2.7s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    6.6s remaining:   15.5s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    6.7s remaining:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "/Users/vpl/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    3.5s remaining:    8.2s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    3.5s remaining:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    2.6s remaining:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    2.6s remaining:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "/Users/vpl/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    5.9s remaining:   13.8s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    5.9s remaining:    2.5s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    2.1s remaining:    4.8s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    2.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.3s remaining:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.4s finished\n",
      "/Users/vpl/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    2.1s remaining:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    2.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    1.2s remaining:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    1.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "/Users/vpl/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    2.6s remaining:    6.0s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    2.6s remaining:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    3.1s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:   16.4s remaining:   38.3s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:   16.5s remaining:    7.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:   20.2s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   3 out of  10 | elapsed:    0.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done   7 out of  10 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "# what kind of analysis\n",
    "analysis = 'ROI-analysis'\n",
    "\n",
    "# define ROIs\n",
    "ROIs = ['hV4', 'LO', 'FEF']\n",
    "# label names which are used to select the labels\n",
    "label_names = [\n",
    "    'Appear',\n",
    "    'Change',\n",
    "    'Vanish'\n",
    "] \n",
    "\n",
    "# declare all path names\n",
    "data_dir = '/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/spm12-glm'     # directory where to look for subjects\n",
    "GLM_name = 'TrickVersionSpecialMoment/'             # Which GLM created the beta images we are going to use\n",
    "GLM_dir = os.path.join(data_dir, GLM_name,'sub-*')  # combine the Path\n",
    "surfer_dir = '/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/surfer/'     # the freesurfer directory\n",
    "subjects = glob.glob(GLM_dir)                # \n",
    "results_dir = '/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/sklearn-decoding'\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.mkdir(results_dir)\n",
    "\n",
    "# outer loop - iterating over subjects\n",
    "for s,sub in enumerate(subjects):\n",
    "    ##########################\n",
    "    # subject specific paths #\n",
    "    ##########################\n",
    "    \n",
    "    # SPM.mat file direcory. Used to get the names of the regressors and the corresponding beta maps\n",
    "    SPM_mat_dir = os.path.join(sub, 'SPM.mat')\n",
    "    # directory where to look for the ROIs\n",
    "    ROI_dir = os.path.join(surfer_dir,'sub-%02i' %(s+1),'ROIs')\n",
    "    # subject specific directory for results\n",
    "    sub_results_dir = os.path.join(results_dir, 'sub-%02i' %(s+1), analysis)\n",
    "    if not os.path.isdir(sub_results_dir):\n",
    "        os.makedirs(sub_results_dir)\n",
    "    \n",
    "    ########################################\n",
    "    # reading in the necessary information #\n",
    "    ########################################\n",
    "    \n",
    "    # From the previously created SPM.mat file we read in information we need\n",
    "    # The filenames of our beta images\n",
    "    SPM_betadict = readmat.load(SPM_mat_dir, isStruct=True)['SPM']['Vbeta']\n",
    "    beta_dirs = [f['fname'] for f in SPM_betadict]\n",
    "    # The corresponding Regressor names - are in form of 'Sn(<run-number>) <Regressor-Name>*bf(1)'\n",
    "    SPM_regressors = readmat.load(SPM_mat_dir,isStruct=True)['SPM']['xX']['name']\n",
    "\n",
    "    # store beta filenames and regressornames in a dictionary\n",
    "    data_dict = {\n",
    "        'Regressors': SPM_regressors,\n",
    "        'BetaNames': beta_dirs\n",
    "    }\n",
    "\n",
    "    # convert dictionary into a pandas DataFrame for further analysis\n",
    "    label_df = pd.DataFrame(data_dict, columns=data_dict.keys())\n",
    "\n",
    "    # This complex loop is necessary to get the run number out of the regressor name\n",
    "    x = [' '.join(re.findall(r\"\\((\\d+)\\)\",string)) for string in label_df.Regressors]\n",
    "    runs = [int(s_filter.split()[0]) for s_filter in x]\n",
    "    # add further data to DataFrame\n",
    "    label_df['Runs'] = runs                     # In which run\n",
    "    label_df['Chunks'] = (label_df.Runs-1)//2   # The chunks (needed for cross validation)\n",
    "    label_df['Labels'] = np.nan                 # Labels\n",
    "    # Check for every entry in Regressors if it contains one of the label names. If so, assign the label name\n",
    "    for l in label_names:\n",
    "        label_df.Labels[label_df.Regressors.str.contains(l)] = l\n",
    "\n",
    "    # again a complex process to throw out regressors of no interest (like realignment)\n",
    "    regressors_of_interest = [True if any(i in n for i in label_names) else False for n in SPM_regressors]\n",
    "    # throw out all rows of regressors of no interest\n",
    "    label_df = label_df.iloc[regressors_of_interest]\n",
    "    \n",
    "    # inner loop - iterating over mask (=ROIs)\n",
    "    for r, roi in enumerate(ROIs):\n",
    "        output_dir = os.path.join(sub_results_dir,roi)   # where to store the results\n",
    "        #if not os.path.isdir(output_dir):\n",
    "        #    os.mkdir(output_dir)\n",
    "        \n",
    "        # call combineROIs with the selected ROI and ROI directory\n",
    "        #ROI = combineROIs(roi, ROI_dir)\n",
    "        maskdir_list = glob.glob(os.path.join(ROI_dir,'*' + roi + '*.nii'))\n",
    "        masklist = []\n",
    "        for mask in maskdir_list:\n",
    "            mask_nii = nib.load(mask)\n",
    "            mask_img = mask_nii.get_fdata()\n",
    "            mask_img = np.asarray(mask_img)\n",
    "            mask_img = mask_img.flatten()\n",
    "            masklist.append(mask_img)\n",
    "            \n",
    "        ROI = np.sum(masklist,axis=0)\n",
    "        ROI = ROI>0\n",
    "        # read in all beta image files, convert them into a one-dimensional numpy array and select the entries of ROI\n",
    "        betas = []                                              # empty list to store data arrays in\n",
    "        for b, beta in enumerate(label_df.BetaNames):\n",
    "            beta_nii = nib.load(os.path.join(subject_dir,beta)) # read in beta NIfTI image\n",
    "            beta_data = beta_nii.get_fdata()                    # get data from NIfTI image\n",
    "            beta_data = beta_data.flatten()                     # convert into one-dimensional array\n",
    "            beta_data = beta_data[ROI]                          # select entries from ROI\n",
    "            beta_data = beta_data[~np.isnan(beta_data)]         # throw out all NaN values. This can happen, when the mask selects Voxels that are on the skull or skin\n",
    "            betas.append(beta_data)                             # append array on betas list\n",
    "\n",
    "        # convert list into numpy array \n",
    "        betas = np.array(betas)\n",
    "        \n",
    "        # the actual decoding\n",
    "        targets = np.asarray(label_df.Labels)\n",
    "        chunks = np.asarray(label_df.Chunks)\n",
    "        if n_permutations > 0:\n",
    "            res = permutation_test_score(\n",
    "                LDA(solver='lsqr', shrinkage='auto'),\n",
    "                betas,\n",
    "                targets,\n",
    "                groups=chunks,\n",
    "                cv=PredefinedSplit(chunks),\n",
    "                n_permutations=n_permutations,\n",
    "                random_state=rng_seed,\n",
    "                n_jobs=n_proc,\n",
    "                verbose=3)\n",
    "            accuracy = res[0]\n",
    "            null_distribution = res[1]\n",
    "            p_value = res[2]\n",
    "        \n",
    "        t_hrs_delta = (time.time() - t_start) / 3600.\n",
    "        \n",
    "        with h5py.File(output_dir, 'w') as f:\n",
    "            f.create_dataset('t_hrs_delta', data=t_hrs_delta)\n",
    "            f.create_dataset('accuracy', data=accuracy)\n",
    "            if n_permutations > 0:\n",
    "                f.create_dataset('null_distribution', data=null_distribution)\n",
    "                f.create_dataset('p_value', data=p_value)\n",
    "                \n",
    "    del label_df\n",
    "    del betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "# TEST FIELD TO DECODE ONLY ONE DECODER ON ONE SUBJECT AND ONE ROI - LATER TO BE USED IN LOOPS #\n",
    "################################################################################################\n",
    "\n",
    "# declare all path names\n",
    "data_dir = '/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/spm12-glm'     # directory where to look for subjects\n",
    "GLM_name = 'TrickVersionSpecialMoment'       # Which GLM created the beta images we are going to use\n",
    "GLM_dir = os.path.join(data_dir, GLM_name)   # combine the Path\n",
    "surfer_dir = '/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/surfer/'     # the freesurfer directory\n",
    "subject_name = 'sub-%02i' %1                        # subject one\n",
    "subject_dir = os.path.join(GLM_dir, subject_name)   # subject directory\n",
    "SPM_mat_dir = os.path.join(subject_dir , 'SPM.mat') # SPM.mat file direcory. Used to get the names of the regressors and the corresponding beta maps\n",
    "ROI_dir = os.path.join(surfer_dir,subject_name,'ROIs')\n",
    "\n",
    "# The ROI to use\n",
    "ROI_name = 'LO'\n",
    "nifti_list = glob.glob(os.path.join(ROI_dir,'*' + '.' + ROI_name + '*.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "for nii in nifti_list:\n",
    "    img = nib.load(nii)\n",
    "    img = img.get_fdata()\n",
    "    img = np.asarray(img,dtype=bool)\n",
    "    img = img.flatten()\n",
    "    l1.append(img)\n",
    "    \n",
    "l2 = np.sum(l1,axis=0)\n",
    "overlap = l2>1\n",
    "l2 = l2>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vpl/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "################################################################################################\n",
    "# TEST FIELD TO DECODE ONLY ONE DECODER ON ONE SUBJECT AND ONE ROI - LATER TO BE USED IN LOOPS #\n",
    "################################################################################################\n",
    "\n",
    "# declare all path names\n",
    "data_dir = '/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/spm12-glm'     # directory where to look for subjects\n",
    "GLM_name = 'TrickVersionSpecialMoment'       # Which GLM created the beta images we are going to use\n",
    "GLM_dir = os.path.join(data_dir, GLM_name)   # combine the Path\n",
    "surfer_dir = '/Users/vpl/Documents/Master_Thesis/DATA/BIDS_playground/derivatives/surfer/'     # the freesurfer directory\n",
    "subject_name = 'sub-%02i' %1                        # subject one\n",
    "subject_dir = os.path.join(GLM_dir, subject_name)   # subject directory\n",
    "SPM_mat_dir = os.path.join(subject_dir , 'SPM.mat') # SPM.mat file direcory. Used to get the names of the regressors and the corresponding beta maps\n",
    "ROI_dir = os.path.join(surfer_dir,subject_name,'ROIs')\n",
    "\n",
    "# The ROI to use\n",
    "ROI_name = 'LO1'\n",
    "\n",
    "# call combineROIs with the selected ROI and ROI directory\n",
    "ROI = combineROIs(ROI_name, ROI_dir)\n",
    "\n",
    "# label names which are used to select the labels\n",
    "label_names = [\n",
    "    'Appear',\n",
    "    'Change',\n",
    "    'Vanish'\n",
    "] \n",
    "\n",
    "# From the previously created SPM.mat file we read in information we need\n",
    "# The filenames of our beta images\n",
    "SPM_betadict = readmat.load(SPM_mat_dir, isStruct=True)['SPM']['Vbeta']\n",
    "betas = [f['fname'] for f in SPM_betadict]\n",
    "# The corresponding Regressor names - are in form of 'Sn(<run-number>) <Regressor-Name>*bf(1)'\n",
    "SPM_regressors = readmat.load(SPM_mat_dir,isStruct=True)['SPM']['xX']['name']\n",
    "\n",
    "# store beta filenames and regressornames in a dictionary\n",
    "data_dict = {\n",
    "    'Regressors': SPM_regressors,\n",
    "    'BetaNames': betas\n",
    "}\n",
    "\n",
    "# convert dictionary into a pandas DataFrame for further analysis\n",
    "label_df = pd.DataFrame(data_dict, columns=data_dict.keys())\n",
    "\n",
    "# This complex loop is necessary to get the run number out of the regressor name\n",
    "x = [' '.join(re.findall(r\"\\((\\d+)\\)\",string)) for string in label_df.Regressors]\n",
    "runs = [int(s_filter.split()[0]) for s_filter in x]\n",
    "# add further data to DataFrame\n",
    "label_df['Runs'] = runs                 # In which run\n",
    "label_df['Chunks'] = label_df.Runs//2   # The chunks (needed for cross validation)\n",
    "label_df['Labels'] = np.nan             # Labels\n",
    "# Check for every entry in Regressors if it contains one of the label names. If so, assign the label name\n",
    "for l in label_names:\n",
    "    label_df.Labels[label_df.Regressors.str.contains(l)] = l\n",
    "\n",
    "# again a complex process to throw out regressors of no interest (like realignment)\n",
    "regressors_of_interest = [True if any(i in n for i in label_names) else False for n in SPM_regressors]\n",
    "# throw out all rows of regressors of no interest\n",
    "label_df = label_df.iloc[regressors_of_interest]\n",
    "\n",
    "# read in all beta image files, convert them into a one-dimensional numpy array and select the entries of ROI\n",
    "betas = []                                              # empty list to store data arrays in\n",
    "for b, beta in enumerate(label_df.BetaNames):\n",
    "    beta_nii = nib.load(os.path.join(subject_dir,beta)) # read in beta NIfTI image\n",
    "    beta_data = beta_nii.get_fdata()                    # get data from NIfTI image\n",
    "    beta_data = beta_data.flatten()                     # convert into one-dimensional array\n",
    "    beta_data = beta_data[ROI]                          # select entries from ROI\n",
    "    beta_data = beta_data[~np.isnan(beta_data)]         # throw out all NaN values. This can happen, when the mask selects Voxels that are on the skull or skin\n",
    "    betas.append(beta_data)                             # append array on betas list\n",
    "\n",
    "# convert list into numpy array \n",
    "betas = np.array(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NIfTIs \n",
    "mask = nib.load(mask_dir)       # check out how this works for multiple masks - probably need to loop over all masks\n",
    "betas = nib.load(batadata_dir)  # check out how this works for non-compressed data - or compress the data\n",
    "\n",
    "# Convert multiple 3D (or one 4D) data to 2D format\n",
    "\n",
    "# define what data should be training and what data should be test data \n",
    "# we want to train on two third and test on the remaining third (we showed videos of balls, cards and sticks appearing, changing color or vanishing)\n",
    "# therefore we train on the videos of two objects and test on the remaining object using cross validation\n",
    "\n",
    "# Do the actual decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# TEST DIFFERENT WAYS OF LOADING MATLAB FILES #\n",
    "###############################################\n",
    "#import tables\n",
    "#import scipy\n",
    "#import h5py\n",
    "#from mat4py import loadmat\n",
    "\n",
    "readmat_example = readmat.load(SPM_mat_dir, isStruct=True)['SPM']['Vbeta']\n",
    "#table_example = tables.open_file(SPM_mat_dir)   # ERROR\n",
    "#scipy_example = scipy.io.loadmat(SPM_mat_dir)\n",
    "#hdf_example = h5py.File(SPM_mat_dir,'r')        # ERROR\n",
    "#data = f.get('data/variable1')\n",
    "#mat4py_example = loadmat(SPM_mat_dir)           # ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineROIs (ROIName, ROIPath, atlas=''):\n",
    "    '''combineROIs(ROIName,ROIPath,atlas='wang15atlas',overlap=0)\n",
    "    Function that returns one combined mask array.\n",
    "    The function itself calls another function (combineRIOs), that actually does the combining\n",
    "    Parameters\n",
    "    ----------\n",
    "    ROIName: The name of your ROI. \n",
    "    ROIPath: The path to your ROI mask images\n",
    "    atlas: Tha name of the used atlas. Default is 'wang15atlas'\n",
    "    overlap: This parameter is not needed when you call the function by your self. \n",
    "        In the recursive iterations of the function this parameter is accumulated and returned to the user.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ROImask: A one dimenstional np.array containing boolian values. \n",
    "    overlap: An interger, telling you how many voxels in your masks overlapped\n",
    "    Example: \n",
    "    combineROIs('V1', 'surfer/sub-01/ROIs')'''\n",
    "    \n",
    "    nifti_list = glob.glob(os.path.join(ROIPath,'*' + atlas + '.' + ROIName + '*.nii'))\n",
    "    mask = combineMasks(nifti_list)\n",
    "    return mask\n",
    "\n",
    "def combineMasks (PathList):\n",
    "    '''combineMasks\n",
    "    Function that combines NIfTI mask images.\n",
    "    The function creates a boolian mask array of an arbitrary number of nifti mask images.\n",
    "    It does so by recursively combining two images using the numpy.bitwise_or function.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    PathList: A list containing the paths.\n",
    "    \n",
    "    Returns:\n",
    "    A one-dimensional boolian mask array.'''\n",
    "    # check if the the list given is empty. In this case an error is returned\n",
    "    if len(PathList)==0:\n",
    "        return False, 0\n",
    "    # check if only one entry is in your list.\n",
    "    # To this point this should not happen, because we have one nifti mask per hemisphere, \n",
    "    # but if deeper brain areas are added, it might happen\n",
    "    elif len(PathList)==1:\n",
    "        ROI_nii = nib.load(PathList[0])\n",
    "        ROI = ROI_nii.get_fdata()\n",
    "        ROI = np.asarray(ROI,dtype=bool)\n",
    "        return ROI.flatten(), 0\n",
    "    # if the list contains two entries, those are combined and returned\n",
    "    elif len (PathList)==2:\n",
    "        ROI0_nii = nib.load(PathList[0])\n",
    "        ROI1_nii = nib.load(PathList[1])\n",
    "        ROI0 = ROI0_nii.get_fdata()\n",
    "        ROI1 = ROI1_nii.get_fdata()\n",
    "        ROI0 = np.asarray(ROI0, dtype=bool)\n",
    "        ROI1 = np.asarray(ROI1, dtype=bool)\n",
    "        ROI0 = ROI0.flatten()\n",
    "        ROI1 = ROI1.flatten()\n",
    "        combined_ROI = np.bitwise_or(ROI0,ROI1)\n",
    "        overlap = sum(np.bitwise_and(ROI0,ROI1))\n",
    "        return combined_ROI\n",
    "    # if the list contains more than two entries the function calls itself, \n",
    "    # but with PathList[1:]\n",
    "    else:\n",
    "        ROI0_nii = nib.load(PathList[0])\n",
    "        ROI0 = ROI0_nii.get_fdata()\n",
    "        ROI0 = np.asarray(ROI0, dtype=bool)\n",
    "        ROI0 = ROI0.flatten()\n",
    "        ROI1 = combineMasks(PathList[1:])\n",
    "        combined_ROI = np.bitwise_or(ROI0,ROI1)\n",
    "        overlap = sum(np.bitwise_and(ROI0,ROI1))\n",
    "        return combined_ROI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
